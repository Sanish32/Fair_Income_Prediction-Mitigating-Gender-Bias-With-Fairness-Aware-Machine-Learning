{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b46ca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "from fairlearn.datasets import fetch_adult\n",
    "from fairlearn.metrics import (\n",
    "    demographic_parity_difference,\n",
    "    demographic_parity_ratio,\n",
    "    equalized_odds_difference,\n",
    "    equalized_odds_ratio,\n",
    ")\n",
    "from fairlearn.reductions import ExponentiatedGradient, DemographicParity\n",
    "\n",
    "# -------------------------\n",
    "# Configuration\n",
    "# -------------------------\n",
    "np.random.seed(42)\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 6)\n",
    "\n",
    "OUTPUT_DIR = Path(\"second\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "437c919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(test_size: float = 0.3, random_state: int = 42):\n",
    "    \"\"\"\n",
    "    Loads the Adult dataset locally and returns scaled train/test splits\n",
    "    plus the protected attribute 'sex'.\n",
    "    \n",
    "    Returns:\n",
    "        X_train_df, X_test_df, y_train, y_test, sex_train, sex_test\n",
    "    \"\"\"\n",
    "\n",
    "    # Column names from UCI Adult dataset definition\n",
    "    columns = [\n",
    "        \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\",\n",
    "        \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\",\n",
    "        \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"\n",
    "    ]\n",
    "\n",
    "    # Load from your local path instead of fetch_adult()\n",
    "    df = pd.read_csv(\"adult/adult.data\", names=columns, sep=\",\", skipinitialspace=True)\n",
    "\n",
    "    # Keep protected attribute\n",
    "    sex = df[\"sex\"].copy()\n",
    "\n",
    "    # Convert target to 0/1\n",
    "    y = df[\"income\"].map({\">50K\": 1, \"<=50K\": 0})\n",
    "\n",
    "    # Drop target from input features\n",
    "    X = df.drop(columns=[\"income\",\"fnlwgt\"])\n",
    "\n",
    "    # One-hot encode categorical features\n",
    "    X_encoded = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "    # Train/validation split (stratified to keep income balance)\n",
    "    X_train, X_test, y_train, y_test, sex_train, sex_test = train_test_split(\n",
    "        X_encoded, y, sex, test_size=test_size,\n",
    "        random_state=random_state, stratify=y\n",
    "    )\n",
    "\n",
    "    # Scale all features (safe even after one-hot encoding)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Convert back to DataFrame\n",
    "    X_train_df = pd.DataFrame(X_train_scaled, columns=X_encoded.columns, index=X_train.index)\n",
    "    X_test_df = pd.DataFrame(X_test_scaled, columns=X_encoded.columns, index=X_test.index)\n",
    "\n",
    "    return X_train_df, X_test_df, y_train, y_test, sex_train, sex_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3775c04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_all_metrics(y_test, y_pred_baseline, y_pred_fair, sex_test):\n",
    "    \"\"\"\n",
    "    Computes fairness metrics for Baseline vs Fair Model.\n",
    "    Returns a DataFrame summary.\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for name, preds in [\n",
    "        (\"Baseline (Unfair)\", y_pred_baseline),\n",
    "        (\"Fair (ExponentiatedGradient)\", y_pred_fair),\n",
    "    ]:\n",
    "        preds = pd.Series(preds, index=y_test.index)\n",
    "\n",
    "        dpd = demographic_parity_difference(y_test, preds, sensitive_features=sex_test)\n",
    "        dpr = demographic_parity_ratio(y_test, preds, sensitive_features=sex_test)\n",
    "        eod = equalized_odds_difference(y_test, preds, sensitive_features=sex_test)\n",
    "        eor = equalized_odds_ratio(y_test, preds, sensitive_features=sex_test)\n",
    "\n",
    "        male_rate = preds[sex_test == \"Male\"].mean()\n",
    "        female_rate = preds[sex_test == \"Female\"].mean()\n",
    "        gap = abs(male_rate - female_rate)\n",
    "\n",
    "        print(f\"\\n{name}\")\n",
    "        print(f\"  DPD: {dpd:.4f}   (â†’ 0 = parity)\")\n",
    "        print(f\"  DPR: {dpr:.4f}   (â†’ 1 = perfect)\")\n",
    "        print(f\"  EOD: {eod:.4f}\")\n",
    "        print(f\"  EOR: {eor:.4f}\")\n",
    "        print(f\"  Male >$50K:   {male_rate:.3f}\")\n",
    "        print(f\"  Female >$50K: {female_rate:.3f}\")\n",
    "        print(f\"  Prediction Gap: {gap:.3f}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Model\": name,\n",
    "            \"DPD\": dpd,\n",
    "            \"DPR\": dpr,\n",
    "            \"EOD\": eod,\n",
    "            \"EOR\": eor,\n",
    "            \"Male_Positive_Rate\": male_rate,\n",
    "            \"Female_Positive_Rate\": female_rate,\n",
    "            \"Gap\": gap\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d4a3f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comparison_visualizations_individual(baseline_acc, fair_acc, fairness_df, model_name, output_dir=\"second\"):\n",
    "    \"\"\"\n",
    "    Create and save individual visualizations for baseline vs fair model.\n",
    "    Each metric is saved as a separate file with the model name in the filename,\n",
    "    including a summary panel showing fairness vs accuracy trade-off.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    models = fairness_df[\"Model\"].values\n",
    "\n",
    "    # ---------------- 1) Accuracy ----------------\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.bar(models, [baseline_acc, fair_acc], color=[\"#e74c3c\", \"#2ecc71\"])\n",
    "    plt.title(f\"{model_name}: Model Accuracy\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    for i, acc in enumerate([baseline_acc, fair_acc]):\n",
    "        plt.text(i, acc + 0.01, f\"{acc:.3f}\", ha=\"center\", fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f\"accuracy_{model_name}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # ---------------- 2) Demographic Parity Difference (DPD) ----------------\n",
    "    plt.figure(figsize=(8,6))\n",
    "    dpd_values = fairness_df[\"DPD\"].values\n",
    "    plt.bar(models, dpd_values, color=[\"#e74c3c\", \"#2ecc71\"])\n",
    "    plt.axhline(0.0, linestyle=\"--\", color=\"black\")\n",
    "    plt.title(f\"{model_name}: Demographic Parity Difference (DPD)\", fontsize=14, fontweight=\"bold\")\n",
    "    for i, val in enumerate(dpd_values):\n",
    "        offset = 0.01 if val >= 0 else -0.03\n",
    "        plt.text(i, val + offset, f\"{val:.3f}\", ha=\"center\", fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f\"dpd_{model_name}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # ---------------- 3) Disparate Impact Ratio (DPR) ----------------\n",
    "    plt.figure(figsize=(8,6))\n",
    "    dpr_values = fairness_df[\"DPR\"].values\n",
    "    plt.bar(models, dpr_values, color=[\"#e74c3c\", \"#2ecc71\"])\n",
    "    plt.axhline(1.0, linestyle=\"--\", color=\"black\", label=\"Perfect = 1.0\")\n",
    "    plt.title(f\"{model_name}: Disparate Impact Ratio (DPR)\", fontsize=14, fontweight=\"bold\")\n",
    "    for i, val in enumerate(dpr_values):\n",
    "        plt.text(i, val + 0.02, f\"{val:.3f}\", ha=\"center\", fontsize=10)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f\"dpr_{model_name}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # ---------------- 4) Equalized Odds Difference (EOD) ----------------\n",
    "    plt.figure(figsize=(8,6))\n",
    "    eod_values = fairness_df[\"EOD\"].values\n",
    "    gap_values = fairness_df[\"Gap\"].values\n",
    "    bars = plt.bar(models, eod_values, color=[\"#e74c3c\", \"#2ecc71\"])\n",
    "    plt.axhline(0.0, linestyle=\"--\", color=\"black\")\n",
    "    plt.title(f\"{model_name}: Equalized Odds Difference (EOD)\", fontsize=14, fontweight=\"bold\")\n",
    "    legend_labels = [f\"{name}\\nEOD: {eod:.3f}, Gap: {gap:.3f}\" for name, eod, gap in zip(models, eod_values, gap_values)]\n",
    "    plt.legend(bars, legend_labels)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f\"eod_{model_name}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # ---------------- 5) Positive Prediction Rates by Gender ----------------\n",
    "    plt.figure(figsize=(8,6))\n",
    "    width = 0.35\n",
    "    x = range(len(models))\n",
    "    male_rates = fairness_df[\"Male_Positive_Rate\"].fillna(0).values\n",
    "    female_rates = fairness_df[\"Female_Positive_Rate\"].fillna(0).values\n",
    "    plt.bar([p - width/2 for p in x], male_rates, width, color=\"#3498db\", label=\"Male\")\n",
    "    plt.bar([p + width/2 for p in x], female_rates, width, color=\"#f39c12\", label=\"Female\")\n",
    "    plt.xticks(x, models, rotation=15, ha=\"right\")\n",
    "    plt.title(f\"{model_name}: Positive Prediction Rates by Gender\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.ylabel(\"Positive Rate\")\n",
    "    legend_labels_rates = [\n",
    "        f\"{m}\\nMale: {mr*100:.1f}%, Female: {fr*100:.1f}%, Gap: {abs(mr-fr)*100:.1f}%\"\n",
    "        for m, mr, fr in zip(models, male_rates, female_rates)\n",
    "    ]\n",
    "    plt.legend(legend_labels_rates, loc=\"upper right\", fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f\"positive_rates_{model_name}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # ---------------- 6) Summary panel (DPD reduction, DPR improvement, Accuracy loss) ----------------\n",
    "    dpd_base = abs(dpd_values[0])\n",
    "    dpd_improve = (1 - abs(dpd_values[1]) / dpd_base) * 100\n",
    "    denom = 1 - dpr_values[0] if (1 - dpr_values[0]) != 0 else 1e-9\n",
    "    dpr_improve = ((dpr_values[1] - dpr_values[0]) / denom) * 100\n",
    "    acc_loss = (baseline_acc - fair_acc) * 100\n",
    "\n",
    "    summary = pd.DataFrame({\n",
    "        \"Metric\": [\"DPD Reduction %\", \"DPR Improvement %\", \"Accuracy Loss %\"],\n",
    "        \"Value\":  [dpd_improve, dpr_improve, acc_loss]\n",
    "    })\n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.barh(summary[\"Metric\"], summary[\"Value\"], color=\"#3498db\")\n",
    "    plt.title(f\"{model_name}: Fairness vs Accuracy Trade-off\", fontsize=14, fontweight=\"bold\")\n",
    "    for i, v in enumerate(summary[\"Value\"]):\n",
    "        plt.text(v + 1, i, f\"{v:.1f}%\", va=\"center\", fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f\"tradeoff_{model_name}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"âœ… All individual plots saved in '{output_dir}' for {model_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3c4509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_table(fairness_df, acc_dict):\n",
    "    rows = []\n",
    "    for idx, row in fairness_df.iterrows():\n",
    "        acc = acc_dict[row[\"Model\"]]\n",
    "        rows.append({\n",
    "            \"Model\": row[\"Model\"],\n",
    "            \"Accuracy\": round(acc, 4),\n",
    "            \"DPD\": round(row[\"DPD\"], 4),\n",
    "            \"DPR\": round(row[\"DPR\"], 4),\n",
    "            \"EOD\": round(row[\"EOD\"], 4),\n",
    "            \"EOR\": round(row[\"EOR\"], 4),\n",
    "            \"Male Positive %\": f\"{row['Male_Positive_Rate']*100:.1f}%\",\n",
    "            \"Female Positive %\": f\"{row['Female_Positive_Rate']*100:.1f}%\"\n",
    "        })\n",
    "    summary_df = pd.DataFrame(rows)\n",
    "    summary_df.to_csv(\"fair_model_results.csv\", index=False)\n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b92635c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LogisticRegression ===\n",
      "Baseline accuracy: 0.8532\n",
      "Fair model accuracy: 0.8358\n",
      "\n",
      "Baseline (Unfair)\n",
      "  DPD: 0.1727   (â†’ 0 = parity)\n",
      "  DPR: 0.3291   (â†’ 1 = perfect)\n",
      "  EOD: 0.0741\n",
      "  EOR: 0.2494\n",
      "  Male >$50K:   0.257\n",
      "  Female >$50K: 0.085\n",
      "  Prediction Gap: 0.173\n",
      "\n",
      "Fair (ExponentiatedGradient)\n",
      "  DPD: 0.0065   (â†’ 0 = parity)\n",
      "  DPR: 0.9621   (â†’ 1 = perfect)\n",
      "  EOD: 0.3174\n",
      "  EOR: 0.5107\n",
      "  Male >$50K:   0.171\n",
      "  Female >$50K: 0.165\n",
      "  Prediction Gap: 0.006\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>DPD</th>\n",
       "      <th>DPR</th>\n",
       "      <th>EOD</th>\n",
       "      <th>EOR</th>\n",
       "      <th>Male_Positive_Rate</th>\n",
       "      <th>Female_Positive_Rate</th>\n",
       "      <th>Gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline (Unfair)</td>\n",
       "      <td>0.172668</td>\n",
       "      <td>0.329137</td>\n",
       "      <td>0.074137</td>\n",
       "      <td>0.249445</td>\n",
       "      <td>0.257382</td>\n",
       "      <td>0.084714</td>\n",
       "      <td>0.172668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fair (ExponentiatedGradient)</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.962076</td>\n",
       "      <td>0.317444</td>\n",
       "      <td>0.510697</td>\n",
       "      <td>0.171233</td>\n",
       "      <td>0.164739</td>\n",
       "      <td>0.006494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model       DPD       DPR       EOD       EOR  \\\n",
       "0             Baseline (Unfair)  0.172668  0.329137  0.074137  0.249445   \n",
       "1  Fair (ExponentiatedGradient)  0.006494  0.962076  0.317444  0.510697   \n",
       "\n",
       "   Male_Positive_Rate  Female_Positive_Rate       Gap  \n",
       "0            0.257382              0.084714  0.172668  \n",
       "1            0.171233              0.164739  0.006494  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All individual plots saved in 'second' for LogisticRegression\n",
      "\n",
      "ðŸ“Š Saved figure for LogisticRegression: second/fair_model_comparison_LogisticRegression.png\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>DPD</th>\n",
       "      <th>DPR</th>\n",
       "      <th>EOD</th>\n",
       "      <th>EOR</th>\n",
       "      <th>Male Positive %</th>\n",
       "      <th>Female Positive %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline (Unfair)</td>\n",
       "      <td>0.8532</td>\n",
       "      <td>0.1727</td>\n",
       "      <td>0.3291</td>\n",
       "      <td>0.0741</td>\n",
       "      <td>0.2494</td>\n",
       "      <td>25.7%</td>\n",
       "      <td>8.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fair (ExponentiatedGradient)</td>\n",
       "      <td>0.8358</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.9621</td>\n",
       "      <td>0.3174</td>\n",
       "      <td>0.5107</td>\n",
       "      <td>17.1%</td>\n",
       "      <td>16.5%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model  Accuracy     DPD     DPR     EOD     EOR  \\\n",
       "0             Baseline (Unfair)    0.8532  0.1727  0.3291  0.0741  0.2494   \n",
       "1  Fair (ExponentiatedGradient)    0.8358  0.0065  0.9621  0.3174  0.5107   \n",
       "\n",
       "  Male Positive % Female Positive %  \n",
       "0           25.7%              8.5%  \n",
       "1           17.1%             16.5%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ CSV saved for LogisticRegression: second/fair_model_results.csv\n",
      "\n",
      "=== RandomForest ===\n",
      "Baseline accuracy: 0.8457\n",
      "Fair model accuracy: 0.8046\n",
      "\n",
      "Baseline (Unfair)\n",
      "  DPD: 0.1856   (â†’ 0 = parity)\n",
      "  DPR: 0.3282   (â†’ 1 = perfect)\n",
      "  EOD: 0.0875\n",
      "  EOR: 0.2615\n",
      "  Male >$50K:   0.276\n",
      "  Female >$50K: 0.091\n",
      "  Prediction Gap: 0.186\n",
      "\n",
      "Fair (ExponentiatedGradient)\n",
      "  DPD: 0.0256   (â†’ 0 = parity)\n",
      "  DPR: 0.9046   (â†’ 1 = perfect)\n",
      "  EOD: 0.0800\n",
      "  EOR: 0.5808\n",
      "  Male >$50K:   0.268\n",
      "  Female >$50K: 0.243\n",
      "  Prediction Gap: 0.026\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>DPD</th>\n",
       "      <th>DPR</th>\n",
       "      <th>EOD</th>\n",
       "      <th>EOR</th>\n",
       "      <th>Male_Positive_Rate</th>\n",
       "      <th>Female_Positive_Rate</th>\n",
       "      <th>Gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline (Unfair)</td>\n",
       "      <td>0.185602</td>\n",
       "      <td>0.328150</td>\n",
       "      <td>0.087469</td>\n",
       "      <td>0.261516</td>\n",
       "      <td>0.276256</td>\n",
       "      <td>0.090653</td>\n",
       "      <td>0.185602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fair (ExponentiatedGradient)</td>\n",
       "      <td>0.025605</td>\n",
       "      <td>0.904635</td>\n",
       "      <td>0.079982</td>\n",
       "      <td>0.580756</td>\n",
       "      <td>0.268493</td>\n",
       "      <td>0.242888</td>\n",
       "      <td>0.025605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model       DPD       DPR       EOD       EOR  \\\n",
       "0             Baseline (Unfair)  0.185602  0.328150  0.087469  0.261516   \n",
       "1  Fair (ExponentiatedGradient)  0.025605  0.904635  0.079982  0.580756   \n",
       "\n",
       "   Male_Positive_Rate  Female_Positive_Rate       Gap  \n",
       "0            0.276256              0.090653  0.185602  \n",
       "1            0.268493              0.242888  0.025605  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All individual plots saved in 'second' for RandomForest\n",
      "\n",
      "ðŸ“Š Saved figure for RandomForest: second/fair_model_comparison_RandomForest.png\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>DPD</th>\n",
       "      <th>DPR</th>\n",
       "      <th>EOD</th>\n",
       "      <th>EOR</th>\n",
       "      <th>Male Positive %</th>\n",
       "      <th>Female Positive %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline (Unfair)</td>\n",
       "      <td>0.8457</td>\n",
       "      <td>0.1856</td>\n",
       "      <td>0.3282</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>0.2615</td>\n",
       "      <td>27.6%</td>\n",
       "      <td>9.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fair (ExponentiatedGradient)</td>\n",
       "      <td>0.8046</td>\n",
       "      <td>0.0256</td>\n",
       "      <td>0.9046</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.5808</td>\n",
       "      <td>26.8%</td>\n",
       "      <td>24.3%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model  Accuracy     DPD     DPR     EOD     EOR  \\\n",
       "0             Baseline (Unfair)    0.8457  0.1856  0.3282  0.0875  0.2615   \n",
       "1  Fair (ExponentiatedGradient)    0.8046  0.0256  0.9046  0.0800  0.5808   \n",
       "\n",
       "  Male Positive % Female Positive %  \n",
       "0           27.6%              9.1%  \n",
       "1           26.8%             24.3%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ CSV saved for RandomForest: second/fair_model_results.csv\n"
     ]
    }
   ],
   "source": [
    "# ==== RUN PIPELINE IN NOTEBOOK ====\n",
    "\n",
    "# 1) Load + preprocess\n",
    "X_train, X_test, y_train, y_test, sex_train, sex_test = load_and_preprocess_data()\n",
    "\n",
    "# 2) Define models to run\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_name, estimator in models.items():\n",
    "    print(f\"\\n=== {model_name} ===\")\n",
    "    \n",
    "    # ---- Baseline (unconstrained) ----\n",
    "    baseline_model = estimator\n",
    "    baseline_model.fit(X_train, y_train)\n",
    "    y_pred_baseline = pd.Series(baseline_model.predict(X_test), index=y_test.index)\n",
    "    baseline_acc = accuracy_score(y_test, y_pred_baseline)\n",
    "    print(f\"Baseline accuracy: {baseline_acc:.4f}\")\n",
    "    \n",
    "    # ---- Fairness-constrained (Exponentiated Gradient + Demographic Parity) ----\n",
    "    mitigator = ExponentiatedGradient(\n",
    "        estimator=estimator,\n",
    "        constraints=DemographicParity(),\n",
    "        max_iter=50\n",
    "    )\n",
    "    mitigator.fit(X_train, y_train, sensitive_features=sex_train)\n",
    "    y_pred_fair = pd.Series(mitigator.predict(X_test), index=y_test.index)\n",
    "    fair_acc = accuracy_score(y_test, y_pred_fair)\n",
    "    print(f\"Fair model accuracy: {fair_acc:.4f}\")\n",
    "    \n",
    "    # ---- Compute fairness metrics ----\n",
    "    fairness_df = measure_all_metrics(y_test, y_pred_baseline, y_pred_fair, sex_test)\n",
    "    display(fairness_df)\n",
    "    \n",
    "    # ---- Visualization ----\n",
    "    create_comparison_visualizations_individual(baseline_acc, fair_acc, fairness_df, model_name, output_dir=\"second\")\n",
    "    print(f\"\\nðŸ“Š Saved figure for {model_name}: second/fair_model_comparison_{model_name}.png\")\n",
    "    \n",
    "    # ---- Summary table ----\n",
    "    acc_dict = {\n",
    "    \"Baseline (Unfair)\": baseline_acc,\n",
    "    \"Fair (ExponentiatedGradient)\": fair_acc\n",
    "}\n",
    "    summary_df = create_summary_table(fairness_df, acc_dict)\n",
    "    display(summary_df)\n",
    "    print(f\"ðŸ“‚ CSV saved for {model_name}: second/fair_model_results.csv\")\n",
    "    \n",
    "    # Store for reference if needed\n",
    "    results.append({\n",
    "        \"model_name\": model_name,\n",
    "        \"baseline_acc\": baseline_acc,\n",
    "        \"fair_acc\": fair_acc,\n",
    "        \"fairness_df\": fairness_df,\n",
    "        \"summary_df\": summary_df\n",
    "    })\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
